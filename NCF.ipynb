{"cells":[{"cell_type":"code","execution_count":null,"id":"11a7f1b3","metadata":{"id":"11a7f1b3"},"outputs":[],"source":["import os                          \n","os.chdir(\"/content/drive/MyDrive/Colab Notebooks\")\n","from torch import nn, cat, mul, load\n","%run GMF.ipynb\n","%run MLP.ipynb\n"]},{"cell_type":"code","execution_count":null,"id":"8847b7fd","metadata":{"id":"8847b7fd","executionInfo":{"status":"error","timestamp":1641313704435,"user_tz":0,"elapsed":242,"user":{"displayName":"Wei Sheng Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02224445722095081810"}},"colab":{"base_uri":"https://localhost:8080/","height":235},"outputId":"53cfd5e0-9433-4dab-cc1d-9c196e5bcc62"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-dcd4bdd3a8f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mNCF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m# create GMF and MLP model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_user_mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"]}],"source":["class NCF(nn.Module):\n","    def __init__(self, num_users, num_items, latent_dim):\n","        super().__init__()\n","        # create GMF and MLP model\n","        self.embedding_user_mlp = nn.Embedding(num_users, latent_dim)\n","        self.embedding_item_mlp = nn.Embedding(num_items, latent_dim)\n","        self.embedding_user_gmf = nn.Embedding(num_users, latent_dim)\n","        self.embedding_item_gmf = nn.Embedding(num_items, latent_dim)\n","\n","        self.fc1_mlp = nn.Linear(2 * latent_dim, 32)\n","        self.fc2_mlp = nn.Linear(32, 16)\n","        self.fc3_mlp = nn.Linear(16, 8)\n","        self.output = nn.Linear(2 * latent_dim, 1)\n","\n","\n","        self.dropout = nn.Dropout(p=0.2)\n","        self.sigmoid = nn.Sigmoid()\n","        self.relu = nn.ReLU()\n","        self.load_weights(num_users, num_items, latent_dim)\n","        \n","        \n","    def forward(self, users, movies):\n","        embedding_user_mlp = self.embedding_user_mlp(users)\n","        embedding_item_mlp = self.embedding_item_mlp(movies)\n","        embedding_user_gmf = self.embedding_user_gmf(users)\n","        embedding_item_gmf = self.embedding_item_gmf(movies)\n","\n","        # GMF first \n","        x_gmf = mul(embedding_user_gmf, embedding_item_gmf)\n","\n","        # MLP\n","        x_mlp = cat([embedding_user_mlp, embedding_item_mlp], dim=1)\n","        x_mlp = self.dropout(self.relu(self.fc1_mlp(x_mlp)))\n","        x_mlp = self.dropout(self.relu(self.fc2_mlp(x_mlp)))\n","        x_mlp = self.fc3_mlp(x_mlp)\n","        # last layer doesn't need relu or dropout\n","\n","        return self.sigmoid(self.output(cat([x_gmf, x_mlp], dim=1)))\n","        \n","        \n","    def load_weights(self, num_users, num_items, latent_dim):\n","\n","        # set alpha value\n","        alpha = 0.5\n","        # initialize NCF model with weights from pretrained model \n","        gmf_model = GMF(num_users, num_items, latent_dim)\n","        mlp_model = MLP(num_users, num_items, latent_dim)\n","        gmf_model.load_state_dict(load('./GMF.pt'))\n","        mlp_model.load_state_dict(load('./MLP2.pt'))\n","\n","        self.output.weight.data = cat([alpha * gmf_model.embedding_layer.weight, (1 - alpha) * mlp_model.fc4.weight], dim=1)\n","        self.output.bias.data = alpha * gmf_model.embedding_layer.bias + (1-alpha)* mlp_model.fc4.bias \n","        "]},{"cell_type":"code","execution_count":null,"id":"061a5d68","metadata":{"id":"061a5d68"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"colab":{"name":"NCF.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}