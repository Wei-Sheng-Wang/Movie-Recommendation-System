{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"6s9Gf3GDtuAV"},"outputs":[],"source":["import os\n","os.chdir(\"/content/drive/MyDrive/Colab Notebooks\")"],"id":"6s9Gf3GDtuAV"},{"cell_type":"code","execution_count":null,"metadata":{"id":"9545658c"},"outputs":[],"source":["import torch\n","import random \n","import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","\n","\n","# import import_ipynb\n","# from importlib import reload\n","%run MLP.ipynb\n","%run GMF.ipynb\n","%run Dataset.ipynb\n","%run NCF.ipynb\n","\n"],"id":"9545658c"},{"cell_type":"code","execution_count":null,"metadata":{"id":"926d5326"},"outputs":[],"source":["def train_test_split(ratings_df):\n","    # rank ratings of each user according to time in descending order, i.e. latest ratings have rank 1\n","    ratings_df['rank_time'] = ratings_df.groupby(['userId'])['timestamp'].rank(method='first', ascending=False)\n","    # create training and testing set\n","    test_set = ratings_df[ratings_df['rank_time'] == 1]\n","    train_set = ratings_df[ratings_df['rank_time'] > 1] \n","\n","    train_set, test_set = train_set[['userId', 'movieId', 'rating']], test_set[['userId', 'movieId', 'rating']]\n","\n","    return train_set, test_set\n","\n","\n","def get_negative_instances(ratings_df) -> pd.DataFrame:\n","\n","    uniq_movies = set(ratings_df['movieId'].unique())\n","\n","    user_item_interaction = ratings_df.groupby('userId')['movieId'].apply(set).reset_index().rename(\n","                columns = {'movieId':'interacted_items'})\n","    \n","    user_item_interaction['negative_instances'] = user_item_interaction['interacted_items'].apply(lambda positive_instances: [x for x in uniq_movies if x not in positive_instances])\n","    \n","    return user_item_interaction[['userId', 'negative_instances']]\n","\n","\n","    \n","# sample negative instances\n","def sample_neg(negative_instances_df, num_neg_samples):  \n","    negative_instances_df['negative_samples'] = negative_instances_df['negative_instances'].apply(lambda x: random.sample(x, num_neg_samples))\n","    \n","    return negative_instances_df[['userId', 'negative_samples']]\n","\n","\n","\n","# train_df columns = {userId, movieId, rating}\n","# negative_instances_df columns = {userId, negative_instances}\n","# return Dataset object\n","def get_dataset(df, negative_instances_df, num_neg_samples=4):\n"," \n","    # sample 4 negative instance per positive instance,\n","    # columns = {userId, negative_samples}\n","    neg_samples_df = sample_neg(negative_instances_df, num_neg_samples)\n","    # merge dataframes to include movies and ratings\n","    neg_samples_df = pd.merge(df, neg_samples_df, on='userId')\n","\n","    users, movies, labels = [], [], []\n","    for row in neg_samples_df.itertuples():\n","        users.append(row.userId)\n","        movies.append(row.movieId)\n","        labels.append(row.rating)\n","        for i in range(num_neg_samples):\n","            users.append(row.userId)\n","            movies.append(row.negative_samples[i])\n","            labels.append(0)\n","\n","    # create custom Dataset \n","    return RatingsDataset(users, movies, labels)\n","\n","\n","    \n","\n","# # actual_ratings_df contains the latest ratings of each user for a moviea\n","# # hundred_neg_samples_df is a dataframe with columns = {userId, negative_samples}, where negative_samples is a list of 100 negative instances of each user\n","def evaluate(users, movies, predictions, test_df, topk=10):\n","    # _, indices = torch.topk(predictions, topk)\n","    # n = len(test_df)\n","    # topk_users, topk_movies = [users[i] for i in indices], [movies[i] for i in indices]\n","    # pred_df = test_df.loc[test_df['userId'].isin(topk_users) and test_df['movieId'].isin(topk_movies)]\n","\n","    # # hit ratio\n","    # hit_ratio = len(pred_df) / n \n","    # # NCDG \n","    # pred_df\n","\n","\n","\n","\n","    pred_df = pd.DataFrame(data={'userId':users.cpu(), 'pred_movieId':movies.cpu(), 'pred_rating':predictions.cpu()})\n","    n = len(test_df)\n","    pred_df.loc[:,'userId'] = pred_df.userId.astype('int')\n","    pred_df.loc[:,'pred_movieId'] = pred_df.pred_movieId.astype('int')\n","    pred_df.loc[:, 'pred_rating'] = pred_df.pred_rating.astype('float')\n","\n","    pred_df.loc[:,'rank'] = pred_df.groupby(['userId'])['pred_rating'].rank(method='first', ascending=False)\n","    pred_df = pred_df.loc[pred_df['rank'] <= topk]\n","    \n","    \n","    pred_ground_df = pd.merge(pred_df, test_df, on='userId')\n","\n","    pred_ground_df = pred_ground_df.loc[pred_ground_df['pred_movieId'] == pred_ground_df['movieId']].copy()\n","    # hit ratio\n","    hit_ratio = len(pred_ground_df) / n\n","\n","    # NCDG\n","    # since each user rates item in the test set, we normalized NCDG by dividing DCG by the total number of unique users\n","    pred_ground_df['ncdg'] = pred_ground_df['rank'].apply(lambda rank: 1.0 / np.log2(rank + 1))\n","    ncdg = pred_ground_df.loc[:,'ncdg'].sum() / n\n","\n","\n","    return hit_ratio, ncdg\n","\n","\n","\n","\n"],"id":"926d5326"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2f3bd0ce"},"outputs":[],"source":["def train(model, train_df, test_df, negative_instances, epochs, batch_size, lr, path):\n","    device = torch.device('cuda')\n","    model.to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","    criterion = torch.nn.BCELoss()\n","\n","    \n","    for e in range(epochs):\n","        if e == 0:\n","            lr = 0.001\n","        else:\n","            lr = 0.0000001\n","        # get training Dataset\n","        train_dataset = get_dataset(train_df, negative_instances, 4)\n","        # create train loader\n","        train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n","        test_dataset = get_dataset(test_df, negative_instances_df, 99)\n","        test_size = len(test_dataset.users)\n","\n","        test_loader = DataLoader(test_dataset, test_size, shuffle=False)\n","\n","        running_loss = 0 \n","        best_loss = 1000\n","        # set model to training mode \n","        model.train()\n","        for users, movies, ratings, in train_loader:\n","            users, movies, ratings = users.to(device), movies.to(device), ratings.to(device)\n","            # zero gradient \n","            optimizer.zero_grad()\n","            # calculate output \n","            output = model.forward(users, movies)\n","            # convert to float\n","            ratings = ratings.float()\n","            # caulcate loss \n","            loss = criterion(output, ratings.unsqueeze(1))\n","            # calculate gradient \n","            loss.backward()\n","            # update weights\n","            optimizer.step()\n","            running_loss += loss.item()\n","\n","        # avg_hit_ratio, avg_ncdg = 0, 0\n","        else:\n","            # set to evaluation mode (turn off dropout)\n","            model.eval()\n","            best_hit_ratio, best_ncdg = 0, 0\n","            # turn off gradient\n","            with torch.no_grad():\n","\n","                for users, movies, _ in test_loader:\n","                    users, movies = users.to(device), movies.to(device)\n","                    # calculate predictions\n","                    output = model.forward(users, movies)\n","                    hit_ratio, ncdg = evaluate(users, movies, output.view(-1), test_df)\n","\n","        if hit_ratio > best_hit_ratio and ncdg > best_ncdg :\n","            torch.save(model.state_dict(), path)\n","            best_hit_ratio = hit_ratio\n","            best_ncdg = ncdg \n","\n","        print(f'iteration {e}: loss per epoch: {running_loss/len(train_loader)}, hit_ratio: {hit_ratio},  NCDG: {ncdg}')\n","\n","    \n","    return model \n","\n","\n","\n","\n","# "],"id":"2f3bd0ce"},{"cell_type":"code","execution_count":null,"metadata":{"id":"VnhBt5PcACNr"},"outputs":[],"source":["# read csv files \n","ratings_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ratings_1m.csv')\n","\n","# convert ratings to binary\n","ratings_df.loc[:,'rating'] = 1\n","ratings_df.userId = ratings_df.userId.astype(int)\n","ratings_df.movieId = ratings_df.movieId.astype(int)\n","\n","# map users \n","movieId_mapping = {val: i for i, val in enumerate(ratings_df['movieId'].unique())}\n","ratings_df['movieId'] = ratings_df['movieId'].map(movieId_mapping)\n","\n","# number of unique users and movies, used for embedding \n","num_uniq_users = ratings_df['userId'].nunique() + 1\n","num_uniq_movies = ratings_df['movieId'].nunique() + 1\n","\n","\n","# columns = {userId, negative_instances}\n","# sample from full dataset\n","negative_instances_df = get_negative_instances(ratings_df)\n","\n","# split into training and test data\n","train_df, ground_truth_df = train_test_split(ratings_df)\n","\n","\n","\n"],"id":"VnhBt5PcACNr"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9a77b2cb","executionInfo":{"status":"ok","timestamp":1641321055532,"user_tz":0,"elapsed":5941213,"user":{"displayName":"Wei Sheng Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02224445722095081810"}},"outputId":"4a59df6d-f90a-48fe-b0b7-b02459a1532a"},"outputs":[{"output_type":"stream","name":"stdout","text":["iteration 0: loss per epoch: 0.22510697111661587, hit_ratio: 0.27417218543046357,  NCDG: 0.14855280059406492\n","iteration 1: loss per epoch: 0.22402956186242087, hit_ratio: 0.405794701986755,  NCDG: 0.35379657023953687\n","iteration 2: loss per epoch: 0.23893930566036617, hit_ratio: 0.38228476821192053,  NCDG: 0.3005272396169019\n","iteration 3: loss per epoch: 0.24004875774783938, hit_ratio: 0.3614238410596026,  NCDG: 0.2564557990954339\n","iteration 4: loss per epoch: 0.2429115022345111, hit_ratio: 0.3653973509933775,  NCDG: 0.2703712801690603\n","iteration 5: loss per epoch: 0.24228314936827902, hit_ratio: 0.37864238410596024,  NCDG: 0.2667390962811503\n","iteration 6: loss per epoch: 0.2275090509311373, hit_ratio: 0.3849337748344371,  NCDG: 0.2801948801924989\n","iteration 7: loss per epoch: 0.22904554407731678, hit_ratio: 0.3923841059602649,  NCDG: 0.28117232035224776\n","iteration 8: loss per epoch: 0.22476906091426033, hit_ratio: 0.40298013245033115,  NCDG: 0.2825791076571699\n","iteration 9: loss per epoch: 0.2210747478696718, hit_ratio: 0.4142384105960265,  NCDG: 0.284234784949382\n","iteration 10: loss per epoch: 0.2261238490088505, hit_ratio: 0.41341059602649005,  NCDG: 0.2840041093653923\n","iteration 11: loss per epoch: 0.20830835136140333, hit_ratio: 0.40844370860927154,  NCDG: 0.2730270501256969\n","iteration 12: loss per epoch: 0.20022694713159137, hit_ratio: 0.42764900662251654,  NCDG: 0.2825780662813044\n","iteration 13: loss per epoch: 0.2010814564334986, hit_ratio: 0.4339403973509934,  NCDG: 0.2847038078881167\n","iteration 14: loss per epoch: 0.19487302558578512, hit_ratio: 0.44950331125827814,  NCDG: 0.2905578822575246\n","iteration 15: loss per epoch: 0.19526201000293064, hit_ratio: 0.45927152317880793,  NCDG: 0.298143325623352\n","iteration 16: loss per epoch: 0.19002664360964133, hit_ratio: 0.4793046357615894,  NCDG: 0.30960547508217956\n","iteration 17: loss per epoch: 0.18753318100049593, hit_ratio: 0.4733443708609272,  NCDG: 0.3072069533873421\n","iteration 18: loss per epoch: 0.18389541607241525, hit_ratio: 0.4783112582781457,  NCDG: 0.3082550275684535\n","iteration 19: loss per epoch: 0.18796282871118403, hit_ratio: 0.48493377483443706,  NCDG: 0.312528261801239\n","iteration 20: loss per epoch: 0.18155232213661252, hit_ratio: 0.48874172185430464,  NCDG: 0.31196865240303906\n","iteration 21: loss per epoch: 0.18537892336853656, hit_ratio: 0.4991721854304636,  NCDG: 0.3199480570448701\n","iteration 22: loss per epoch: 0.18038934930289569, hit_ratio: 0.4922185430463576,  NCDG: 0.31137418253531524\n","iteration 23: loss per epoch: 0.18245047757045035, hit_ratio: 0.5029801324503311,  NCDG: 0.3195742335492145\n","iteration 24: loss per epoch: 0.18076065079155473, hit_ratio: 0.49354304635761587,  NCDG: 0.31395407167861517\n","iteration 25: loss per epoch: 0.1784266622204482, hit_ratio: 0.5028145695364239,  NCDG: 0.32485087531767975\n","iteration 26: loss per epoch: 0.17809568017727698, hit_ratio: 0.5153973509933775,  NCDG: 0.3371686380669333\n","iteration 27: loss per epoch: 0.18213143835943707, hit_ratio: 0.506953642384106,  NCDG: 0.3385727867424875\n","iteration 28: loss per epoch: 0.18349159496185713, hit_ratio: 0.5158940397350993,  NCDG: 0.33979959419506023\n","iteration 29: loss per epoch: 0.1883088233380457, hit_ratio: 0.5163907284768212,  NCDG: 0.33533586255430053\n","iteration 30: loss per epoch: 0.18146850130671266, hit_ratio: 0.5274834437086092,  NCDG: 0.3508512271919348\n","iteration 31: loss per epoch: 0.18206300992919242, hit_ratio: 0.5347682119205298,  NCDG: 0.3609592706531902\n","iteration 32: loss per epoch: 0.18363557475188225, hit_ratio: 0.5397350993377483,  NCDG: 0.35064897480219204\n","iteration 33: loss per epoch: 0.18431018618200132, hit_ratio: 0.5370860927152318,  NCDG: 0.3454248883726932\n","iteration 34: loss per epoch: 0.18741932676011347, hit_ratio: 0.5501655629139073,  NCDG: 0.35271221565723104\n","iteration 35: loss per epoch: 0.1863868755586457, hit_ratio: 0.5508278145695364,  NCDG: 0.3625355032460294\n","iteration 36: loss per epoch: 0.18457961579247004, hit_ratio: 0.5437086092715232,  NCDG: 0.35181583823092155\n","iteration 37: loss per epoch: 0.18558873053809335, hit_ratio: 0.5455298013245033,  NCDG: 0.34966552476122786\n","iteration 38: loss per epoch: 0.18630110688057866, hit_ratio: 0.5531456953642384,  NCDG: 0.35522875195721376\n","iteration 39: loss per epoch: 0.1887595152676348, hit_ratio: 0.5617549668874172,  NCDG: 0.3741293092244115\n","iteration 40: loss per epoch: 0.18496669870369134, hit_ratio: 0.56341059602649,  NCDG: 0.37048460199975314\n","iteration 41: loss per epoch: 0.1886897937600243, hit_ratio: 0.5566225165562914,  NCDG: 0.3664356518491965\n","iteration 42: loss per epoch: 0.1871895169854035, hit_ratio: 0.5571192052980133,  NCDG: 0.3637070843428888\n","iteration 43: loss per epoch: 0.1868854005600329, hit_ratio: 0.5571192052980133,  NCDG: 0.3597624491471442\n","iteration 44: loss per epoch: 0.1913948217561306, hit_ratio: 0.5629139072847682,  NCDG: 0.3586706776397622\n","iteration 45: loss per epoch: 0.18807561607978251, hit_ratio: 0.562748344370861,  NCDG: 0.36024697241037695\n","iteration 46: loss per epoch: 0.190547051325092, hit_ratio: 0.5678807947019867,  NCDG: 0.3680128254325903\n","iteration 47: loss per epoch: 0.18769535672781745, hit_ratio: 0.5670529801324503,  NCDG: 0.3613877916063561\n","iteration 48: loss per epoch: 0.18756187833555543, hit_ratio: 0.5612582781456954,  NCDG: 0.3585779575299667\n","iteration 49: loss per epoch: 0.18789962502667415, hit_ratio: 0.5683774834437086,  NCDG: 0.36538347624852685\n","iteration 50: loss per epoch: 0.18677384441685654, hit_ratio: 0.5597682119205298,  NCDG: 0.35974323293441396\n","iteration 51: loss per epoch: 0.19476046543831205, hit_ratio: 0.5668874172185431,  NCDG: 0.36515370103012185\n","iteration 52: loss per epoch: 0.19360865593510598, hit_ratio: 0.5735099337748344,  NCDG: 0.3575272710531706\n","iteration 53: loss per epoch: 0.19723806136950292, hit_ratio: 0.5698675496688742,  NCDG: 0.3605188942591882\n","iteration 54: loss per epoch: 0.19569777717507086, hit_ratio: 0.5763245033112583,  NCDG: 0.36514836239051535\n","iteration 55: loss per epoch: 0.19275109056709128, hit_ratio: 0.5705298013245033,  NCDG: 0.3637671438387961\n","iteration 56: loss per epoch: 0.1951019557039252, hit_ratio: 0.5697019867549669,  NCDG: 0.36107486048142917\n","iteration 57: loss per epoch: 0.1951424582213016, hit_ratio: 0.5745033112582781,  NCDG: 0.3702278229091312\n","iteration 58: loss per epoch: 0.20222290408682358, hit_ratio: 0.5733443708609272,  NCDG: 0.3700720018255943\n","iteration 59: loss per epoch: 0.19569993827164708, hit_ratio: 0.573841059602649,  NCDG: 0.3667481742873627\n","iteration 60: loss per epoch: 0.20328817089896994, hit_ratio: 0.5745033112582781,  NCDG: 0.35893447034690634\n","iteration 61: loss per epoch: 0.19770346451211152, hit_ratio: 0.5802980132450332,  NCDG: 0.3614624066811902\n","iteration 62: loss per epoch: 0.19818054160525458, hit_ratio: 0.5753311258278145,  NCDG: 0.36275211223371645\n","iteration 63: loss per epoch: 0.20320754872383878, hit_ratio: 0.5736754966887417,  NCDG: 0.3570690728567553\n","iteration 64: loss per epoch: 0.20212158060300078, hit_ratio: 0.5768211920529801,  NCDG: 0.35747363253222864\n","iteration 65: loss per epoch: 0.20234973376444365, hit_ratio: 0.5791390728476821,  NCDG: 0.3645841144302295\n","iteration 66: loss per epoch: 0.1993724283959783, hit_ratio: 0.5751655629139073,  NCDG: 0.36104112297571633\n","iteration 67: loss per epoch: 0.1997202506292915, hit_ratio: 0.5745033112582781,  NCDG: 0.3599685093510593\n","iteration 68: loss per epoch: 0.20449340034198357, hit_ratio: 0.5791390728476821,  NCDG: 0.3575430849587921\n","iteration 69: loss per epoch: 0.20571048185843213, hit_ratio: 0.5798013245033112,  NCDG: 0.36402043950230645\n","iteration 70: loss per epoch: 0.2048420263202039, hit_ratio: 0.5779801324503311,  NCDG: 0.3663144145407012\n","iteration 71: loss per epoch: 0.2118594661870704, hit_ratio: 0.5832781456953643,  NCDG: 0.3631182457042599\n","iteration 72: loss per epoch: 0.20580687689081636, hit_ratio: 0.5794701986754967,  NCDG: 0.358772959325002\n","iteration 73: loss per epoch: 0.2044550576331208, hit_ratio: 0.5781456953642384,  NCDG: 0.3614951317754675\n","iteration 74: loss per epoch: 0.19950496118244457, hit_ratio: 0.5890728476821192,  NCDG: 0.36912839495140437\n","iteration 75: loss per epoch: 0.2027904477209476, hit_ratio: 0.5781456953642384,  NCDG: 0.3560044076215699\n","iteration 76: loss per epoch: 0.20489162056510107, hit_ratio: 0.583112582781457,  NCDG: 0.36214143747362176\n","iteration 77: loss per epoch: 0.20876117495061938, hit_ratio: 0.5710264900662252,  NCDG: 0.3500805295849508\n","iteration 78: loss per epoch: 0.20646509379056396, hit_ratio: 0.5693708609271523,  NCDG: 0.35146931431107375\n","iteration 79: loss per epoch: 0.20798601898388608, hit_ratio: 0.5693708609271523,  NCDG: 0.3535664511723563\n","iteration 80: loss per epoch: 0.20914191493793488, hit_ratio: 0.5786423841059603,  NCDG: 0.35568687733878374\n","iteration 81: loss per epoch: 0.2118310898009836, hit_ratio: 0.5697019867549669,  NCDG: 0.3499917434132743\n","iteration 82: loss per epoch: 0.20744499251421417, hit_ratio: 0.5824503311258278,  NCDG: 0.35992534036919677\n","iteration 83: loss per epoch: 0.2056413940160251, hit_ratio: 0.5809602649006622,  NCDG: 0.359262535912098\n","iteration 84: loss per epoch: 0.2088255469177641, hit_ratio: 0.5826158940397351,  NCDG: 0.3551964344432335\n","iteration 85: loss per epoch: 0.20659228683612302, hit_ratio: 0.5779801324503311,  NCDG: 0.3523276442153897\n","iteration 86: loss per epoch: 0.21250145577599514, hit_ratio: 0.5768211920529801,  NCDG: 0.34977427429591457\n","iteration 87: loss per epoch: 0.2114663637782398, hit_ratio: 0.5817880794701987,  NCDG: 0.35860743868983097\n","iteration 88: loss per epoch: 0.21958528231311034, hit_ratio: 0.5847682119205299,  NCDG: 0.35585994758748646\n","iteration 89: loss per epoch: 0.2106206076798481, hit_ratio: 0.5857615894039735,  NCDG: 0.35790789070959\n","iteration 90: loss per epoch: 0.21958918851154793, hit_ratio: 0.5731788079470199,  NCDG: 0.34499978935546116\n","iteration 91: loss per epoch: 0.21116267672989036, hit_ratio: 0.580794701986755,  NCDG: 0.3536296426182426\n","iteration 92: loss per epoch: 0.21320353444055212, hit_ratio: 0.5731788079470199,  NCDG: 0.3427110758963113\n","iteration 93: loss per epoch: 0.21658907203336236, hit_ratio: 0.5794701986754967,  NCDG: 0.3432356932194416\n","iteration 94: loss per epoch: 0.2173423206830586, hit_ratio: 0.5788079470198676,  NCDG: 0.3501769435905257\n","iteration 95: loss per epoch: 0.21733861102908006, hit_ratio: 0.5860927152317881,  NCDG: 0.3559777552860459\n","iteration 96: loss per epoch: 0.21547137353926488, hit_ratio: 0.5846026490066225,  NCDG: 0.3489081347101765\n","iteration 97: loss per epoch: 0.22102999546532406, hit_ratio: 0.5756622516556291,  NCDG: 0.34556496627498834\n","iteration 98: loss per epoch: 0.2276294480574519, hit_ratio: 0.5846026490066225,  NCDG: 0.3562754809465771\n","iteration 99: loss per epoch: 0.21989164238943168, hit_ratio: 0.579635761589404,  NCDG: 0.35160740257938417\n"]}],"source":["# create GMF, MLP and NCF models\n","# mlp_model = MLP(num_users=num_uniq_users + 1, num_items=num_uniq_movies + 1, latent_dim=8)\n","# mlp_model = train(mlp_model, train_df, ground_truth_df, negative_instances_df, 100, 256, 0.0005, path='./MLP.pt')\n","\n","# gmf_model = GMF(num_users=num_uniq_users + 1, num_items=num_uniq_movies + 1, latent_dim=8)\n","# gmf_model = train(gmf_model, train_df, ground_truth_df, negative_instances_df, 100, 512, path='./GMF.pt')\n","\n","ncf_model = NCF(num_users=num_uniq_users+1, num_items=num_uniq_movies+1, latent_dim=8)\n","ncf_model = train(ncf_model, train_df, ground_truth_df, negative_instances_df, 100, 256, lr=0.001, path='NCF.pt')\n","\n","# # save GMF, MLP model\n","# torch.save(gmf_model.state_dict(), './GMF.pt')\n","# torch.save(mlp_model.state_dict(), './MLP.pt')\n"],"id":"9a77b2cb"}],"metadata":{"colab":{"collapsed_sections":[],"name":"main.ipynb","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}